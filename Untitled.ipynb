{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "316d5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hosting static project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e70ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Tue Aug 29 09:40:39 2023\n",
    "\n",
    "@author: Nikhil Yadav\n",
    "\"\"\"\n",
    "\n",
    "#**************** IMPORT PACKAGES ********************\n",
    "from flask import Flask, render_template, request, flash, redirect, url_for\n",
    "from flask_mail import Mail, Message\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "\n",
    "import re\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from textblob import TextBlob\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#************ FLASK *****************\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "# Configure Flask-Mail settings\n",
    "app.config['MAIL_SERVER'] = 'smtp.gmail.com'\n",
    "app.config['MAIL_PORT'] = 587\n",
    "app.config['MAIL_USE_TLS'] = True\n",
    "app.config['MAIL_USERNAME'] = 'itlearnix@gmail.com'\n",
    "app.config['MAIL_PASSWORD'] = 'veyqttrtaoahxsga'\n",
    "app.config['MAIL_DEFAULT_SENDER'] = 'itlearnix@gmail.com'\n",
    "\n",
    "# Configure the OAuth instances\n",
    "mail = Mail(app)\n",
    "\n",
    "#To control caching so as to save and retrieve plot figs on client side\n",
    "@app.after_request\n",
    "def add_header(response):\n",
    "    response.headers['Pragma'] = 'no-cache'\n",
    "    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n",
    "    response.headers['Expires'] = '0'\n",
    "    return response\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/stock-predictions')\n",
    "def stock_predictions():\n",
    "    return render_template('stock-predictions.html')\n",
    "\n",
    "@app.route('/coinvert')\n",
    "def coinvert():\n",
    "    return render_template('coinvert.html')\n",
    "\n",
    "@app.route('/about')\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route('/contact')\n",
    "def contact():\n",
    "    return render_template('contact.html')\n",
    "\n",
    "@app.route('/contact-form', methods=['POST'])\n",
    "def contact_form():\n",
    "    if request.method == 'POST':\n",
    "        name = request.form.get('name')\n",
    "        email = request.form.get('email')\n",
    "        subject = request.form.get('subject')\n",
    "        message = request.form.get('message')\n",
    "\n",
    "        # Create the email message for team member\n",
    "        team_subject = 'New Contact Form Submission'\n",
    "        team_body = f\"Name: {name}\\nEmail: {email}\\nSubject: {subject}\\nMessage: {message}\"\n",
    "        team_recipients = ['yadavnikhilrao@gmail.com']\n",
    "\n",
    "        # Send email to team member\n",
    "        team_msg = Message(subject=team_subject, body=team_body, recipients=team_recipients)\n",
    "        mail.send(team_msg)\n",
    "\n",
    "\n",
    "\n",
    "        return render_template('message-sent.html')\n",
    "    \n",
    "\n",
    "@app.route('/result', methods=['POST'])\n",
    "def result():\n",
    "    symbol = request.form['symbol']\n",
    "\n",
    "    # **************** FUNCTIONS TO FETCH DATA ***************************\n",
    "    \n",
    "    def get_historical(quote):\n",
    "        end = datetime.now()\n",
    "        start = datetime(end.year - 2, end.month, end.day)\n",
    "        data = yf.download(quote, start=start, end=end)\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv('' + quote + '.csv')\n",
    "        if df.empty:\n",
    "            ts = TimeSeries(key='N6A6QT6IBFJOPJ70', output_format='pandas')\n",
    "            data, meta_data = ts.get_daily_adjusted(symbol='NSE:' + quote, outputsize='full')\n",
    "            # Format df\n",
    "            # Last 2 yrs rows => 502, in ascending order => ::-1\n",
    "            data = data.head(503).iloc[::-1]\n",
    "            data = data.reset_index()\n",
    "            # Keep Required cols only\n",
    "            df = pd.DataFrame()\n",
    "            df['Date'] = data['date']\n",
    "            df['Open'] = data['1. open']\n",
    "            df['High'] = data['2. high']\n",
    "            df['Low'] = data['3. low']\n",
    "            df['Close'] = data['4. close']\n",
    "            df['Adj Close'] = data['5. adjusted close']\n",
    "            df['Volume'] = data['6. volume']\n",
    "            df.to_csv('' + quote + '.csv', index=False)\n",
    "        return\n",
    "\n",
    "    # ******************** ARIMA SECTION ********************\n",
    "    \n",
    "    # Define the parser function\n",
    "    def parser(x):\n",
    "        return datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "    # ************* ARIMA SECTION ********************\n",
    "    \n",
    "    def ANN_ALGO(df):\n",
    "        uniqueVals = df[\"Code\"].unique()\n",
    "        len(uniqueVals)\n",
    "        df = df.set_index(\"Code\")\n",
    "\n",
    "        def ann_model(train, test):\n",
    "            scaler = MinMaxScaler()\n",
    "            train_scaled = scaler.fit_transform(train)\n",
    "            test_scaled = scaler.transform(test)\n",
    "\n",
    "            X_train, y_train = train_scaled[:-1], train_scaled[1:]\n",
    "            X_test, y_test = test_scaled[:-1], test_scaled[1:]\n",
    "\n",
    "            model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "            return y_pred_inv\n",
    "\n",
    "        for company in uniqueVals[:10]:\n",
    "            data = (df.loc[company, :]).reset_index()\n",
    "            data['Price'] = data['Close']\n",
    "            Quantity_date = data[['Price', 'Date']]\n",
    "            Quantity_date.index = Quantity_date['Date'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "            Quantity_date['Price'] = Quantity_date['Price'].map(lambda x: float(x))\n",
    "            Quantity_date = Quantity_date.fillna(Quantity_date.bfill())\n",
    "            Quantity_date = Quantity_date.drop(['Date'], axis=1)\n",
    "\n",
    "            fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "            plt.plot(Quantity_date)\n",
    "            plt.savefig('static/Trends.png')\n",
    "            plt.close(fig)\n",
    "\n",
    "            quantity = Quantity_date.values\n",
    "            size = int(len(quantity) * 0.80)\n",
    "            train, test = quantity[0:size], quantity[size:len(quantity)]\n",
    "\n",
    "            predictions = ann_model(train, test)\n",
    "\n",
    "            fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "            plt.plot(test[1:], label='Actual Price')\n",
    "            plt.plot(predictions, label='Predicted Price')\n",
    "            plt.legend(loc=4)\n",
    "            plt.savefig('static/ARIMA.png')\n",
    "            plt.close(fig)\n",
    "\n",
    "            #print()\n",
    "            ann_pred = predictions[-1][0]\n",
    "            print(\"Tomorrow's\", quote, \"Closing Price Prediction by ANN:\", ann_pred)\n",
    "\n",
    "            error_ann = math.sqrt(mean_squared_error(test[1:], predictions))\n",
    "            print(\"ANN RMSE:\", error_ann)\n",
    "\n",
    "            return ann_pred, error_ann\n",
    "        \n",
    "    # ************* GaussianProcessRegressor SECTION **********************\n",
    "\n",
    "    def PolynomialRegression_ALGO(df):\n",
    "        dataset_train = df.iloc[0:int(0.8 * len(df)), :]\n",
    "        dataset_test = df.iloc[int(0.8 * len(df)):, :]\n",
    "        training_set = dataset_train.iloc[:, 4:5].values\n",
    "\n",
    "        sc = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(7, len(training_set_scaled)):\n",
    "            X_train.append(training_set_scaled[i - 7:i, 0])\n",
    "            y_train.append(training_set_scaled[i, 0])\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        X_forecast = np.append(X_train[-1, 1:], y_train[-1])\n",
    "\n",
    "        poly = PolynomialFeatures(degree=2)  # You can adjust the degree as needed\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "        X_forecast_poly = poly.transform(np.array(X_forecast).reshape(1, -1))\n",
    "\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train_poly, y_train)\n",
    "\n",
    "        real_stock_price = dataset_test.iloc[:, 4:5].values\n",
    "\n",
    "        dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
    "        testing_set = dataset_total[len(dataset_total) - len(dataset_test) - 7:].values\n",
    "        testing_set = testing_set.reshape(-1, 1)\n",
    "\n",
    "        testing_set = sc.transform(testing_set)\n",
    "\n",
    "        X_test = []\n",
    "        for i in range(7, len(testing_set)):\n",
    "            X_test.append(testing_set[i - 7:i, 0])\n",
    "        X_test = np.array(X_test)\n",
    "        X_test_poly = poly.transform(X_test)\n",
    "\n",
    "        predicted_stock_price_poly = regressor.predict(X_test_poly)\n",
    "        predicted_stock_price = sc.inverse_transform(predicted_stock_price_poly.reshape(-1, 1))\n",
    "\n",
    "        fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "        plt.plot(real_stock_price, label='Actual Price')\n",
    "        plt.plot(predicted_stock_price, label='Predicted Price')\n",
    "        plt.legend(loc=4)\n",
    "        plt.savefig('static/LSTM.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        error_poly = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "\n",
    "        forecasted_stock_price_poly = regressor.predict(X_forecast_poly)\n",
    "        forecasted_stock_price = sc.inverse_transform(forecasted_stock_price_poly.reshape(-1, 1))\n",
    "\n",
    "        poly_pred = forecasted_stock_price[0, 0]\n",
    "        print()\n",
    "        print(\"Tomorrow's\", quote, \"Closing Price Prediction by Polynomial Regression:\", poly_pred)\n",
    "        print(\"Polynomial Regression RMSE:\", error_poly)\n",
    "\n",
    "        return poly_pred, error_poly\n",
    "\n",
    "    \n",
    "    #***************** LINEAR REGRESSION SECTION ******************  \n",
    "    \n",
    "    def LIN_REG_ALGO(df):\n",
    "        #No of days to be forcasted in future\n",
    "        forecast_out = int(7)\n",
    "        #Price after n days\n",
    "        df['Close after n days'] = df['Close'].shift(-forecast_out)\n",
    "        #New df with only relevant data\n",
    "        df_new=df[['Close','Close after n days']]\n",
    "\n",
    "        #Structure data for train, test & forecast\n",
    "        #lables of known data, discard last 35 rows\n",
    "        y =np.array(df_new.iloc[:-forecast_out,-1])\n",
    "        y=np.reshape(y, (-1,1))\n",
    "        #all cols of known data except lables, discard last 35 rows\n",
    "        X=np.array(df_new.iloc[:-forecast_out,0:-1])\n",
    "        #Unknown, X to be forecasted\n",
    "        X_to_be_forecasted=np.array(df_new.iloc[-forecast_out:,0:-1])\n",
    "        \n",
    "        #Traning, testing to plot graphs, check accuracy\n",
    "        X_train=X[0:int(0.8*len(df)),:]\n",
    "        X_test=X[int(0.8*len(df)):,:]\n",
    "        y_train=y[0:int(0.8*len(df)),:]\n",
    "        y_test=y[int(0.8*len(df)):,:]\n",
    "        \n",
    "        # Feature Scaling===Normalization\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        X_to_be_forecasted=sc.transform(X_to_be_forecasted)\n",
    "        \n",
    "        #Training\n",
    "        clf = LinearRegression(n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        #Testing\n",
    "        y_test_pred=clf.predict(X_test)\n",
    "        y_test_pred=y_test_pred*(1.04)\n",
    "        import matplotlib.pyplot as plt2\n",
    "        fig = plt2.figure(figsize=(10.2, 6), dpi=65)\n",
    "        plt2.plot(y_test,label='Actual Price' )\n",
    "        plt2.plot(y_test_pred,label='Predicted Price')\n",
    "        \n",
    "        plt2.legend(loc=4)\n",
    "        plt2.savefig('static/LR.png')\n",
    "        plt2.close(fig)\n",
    "        \n",
    "        error_lr = math.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        \n",
    "        #Forecasting\n",
    "        forecast_set = clf.predict(X_to_be_forecasted)\n",
    "        forecast_set=forecast_set*(1.04)\n",
    "        mean=forecast_set.mean()\n",
    "        lr_pred=forecast_set[0,0]\n",
    "        print()\n",
    "        print(\"Tomorrow's \",quote,\" Closing Price Prediction by Linear Regression: \",lr_pred)\n",
    "        print(\"Linear Regression RMSE:\",error_lr)\n",
    "        return df, lr_pred, forecast_set, mean, error_lr\n",
    "    \n",
    "    \n",
    "\n",
    "    #**************** SENTIMENT ANALYSIS **************************\n",
    "    \n",
    "    def retrieve_news_sentiment(symbol, api_key):\n",
    "        \n",
    "        # Define the URL for the news API\n",
    "        news_api_url = f'https://newsapi.org/v2/everything?q={symbol} stock&apiKey={api_key}'\n",
    "\n",
    "        try:\n",
    "            # Send an HTTP GET request to the news API\n",
    "            response = requests.get(news_api_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Parse the JSON response\n",
    "                news_data = response.json()\n",
    "\n",
    "                # Check if news articles are available\n",
    "                if 'articles' in news_data and len(news_data['articles']) > 0:\n",
    "                    news_list = []  # List of news headlines alongside polarity\n",
    "                    global_polarity = 0  # Polarity of all news headlines\n",
    "                    news_headlines_list = []  # List of news headlines only\n",
    "                    pos = 0  # Num of positive headlines\n",
    "                    neg = 0  # Num of negative headlines\n",
    "                    neutral = 0  # Num of neutral headlines\n",
    "\n",
    "                    for article in news_data['articles']:\n",
    "                        news_text = article['title']\n",
    "\n",
    "                        # Analyze the sentiment of the news headline\n",
    "                        analysis = TextBlob(news_text)\n",
    "                        polarity = analysis.sentiment.polarity\n",
    "                        global_polarity += polarity\n",
    "\n",
    "                        # Categorize the sentiment of the news headline\n",
    "                        if polarity > 0:\n",
    "                            sentiment = \"Positive\"\n",
    "                            pos += 1\n",
    "                        elif polarity < 0:\n",
    "                            sentiment = \"Negative\"\n",
    "                            neg += 1\n",
    "                        else:\n",
    "                            sentiment = \"Neutral\"\n",
    "                            neutral += 1\n",
    "\n",
    "                        news_list.append((news_text, sentiment))\n",
    "                        news_headlines_list.append(news_text)\n",
    "\n",
    "                    # Determine the overall sentiment based on global_polarity\n",
    "                    if global_polarity > 0:\n",
    "                        overall_sentiment = \"Overall Positive\"\n",
    "                    elif global_polarity < 0:\n",
    "                        overall_sentiment = \"Overall Negative\"\n",
    "                    else:\n",
    "                        overall_sentiment = \"Overall Neutral\"\n",
    "\n",
    "                    # Create a pie chart for sentiment analysis\n",
    "                    sentiment_data = pd.DataFrame({'Sentiment': ['Positive', 'Negative', 'Neutral'],\n",
    "                                               'Count': [pos, neg, neutral]})\n",
    "                    plt.figure(figsize=(4.9, 4.9))\n",
    "                    plt.pie(sentiment_data['Count'], labels=sentiment_data['Sentiment'], autopct='%1.1f%%', startangle=100)\n",
    "                    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "                    # Save the figure as 'static/SA.png'\n",
    "                    plt.savefig('static/SA.png')\n",
    "\n",
    "                    # Close the figure\n",
    "                    plt.close()\n",
    "\n",
    "                    return global_polarity, news_list, overall_sentiment, pos, neg, neutral\n",
    "                else:\n",
    "                    return 0, [], \"No News Found\", 0, 0, 0\n",
    "            else:\n",
    "                return 0, [], f\"Failed to Fetch News (Status Code: {response.status_code})\", 0, 0, 0\n",
    "\n",
    "        except Exception as e:\n",
    "            return 0, [], f\"Error: {str(e)}\", 0, 0, 0\n",
    "\n",
    "        \n",
    "    def recommending(df, global_polarity,today_stock,mean):\n",
    "        if today_stock.iloc[-1]['Close'] < mean:\n",
    "            if global_polarity > 0:\n",
    "                idea=\"RISE\"\n",
    "                decision=\"BUY\"\n",
    "                print()\n",
    "                print(\"##############################################################################\")\n",
    "                print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "            elif global_polarity <= 0:\n",
    "                idea=\"FALL\"\n",
    "                decision=\"SELL\"\n",
    "                print()\n",
    "                print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "        else:\n",
    "            idea=\"FALL\"\n",
    "            decision=\"SELL\"\n",
    "            print()\n",
    "            print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "        return idea, decision\n",
    "    \n",
    "    \n",
    "    #**************GET DATA ***************************************\n",
    "    \n",
    "    quote=symbol\n",
    "    \n",
    "    #Try-except to check if valid stock symbol\n",
    "    try:\n",
    "        get_historical(quote)\n",
    "    except:\n",
    "        return render_template('stock-predictions.html',msg=\"Stock Symbol Not Found. Please Enter a Valid Stock Symbol\")\n",
    "    else:\n",
    "    \n",
    "        #************** PREPROCESSUNG ***********************\n",
    "        \n",
    "        df = pd.read_csv(''+quote+'.csv')\n",
    "        print(\"Today's\",quote,\"Stock Data: \")\n",
    "        today_stock=df.iloc[-1:]\n",
    "        print(today_stock)\n",
    "        df = df.dropna()\n",
    "        code_list=[]\n",
    "        for i in range(0,len(df)):\n",
    "            code_list.append(quote)\n",
    "        df2=pd.DataFrame(code_list,columns=['Code'])\n",
    "        df2 = pd.concat([df2, df], axis=1)\n",
    "        df=df2\n",
    "\n",
    "\n",
    "        arima_pred, error_arima=ANN_ALGO(df)\n",
    "        lstm_pred, error_lstm=PolynomialRegression_ALGO(df)\n",
    "        df, lr_pred, forecast_set,mean,error_lr=LIN_REG_ALGO(df)\n",
    "        \n",
    "        # Assuming you have an 'api_key' variable defined with your API key\n",
    "        api_key = 'caae80f5ad8b451e9fc0856027ddbb34'\n",
    "        #symbol = quote\n",
    "\n",
    "        # Call the retrieve_news_sentiment function with the 'api_key' argument\n",
    "        polarity, news_list, overall_sentiment, pos, neg, neutral = retrieve_news_sentiment(quote, api_key)\n",
    "        \n",
    "        idea, decision=recommending(df, polarity,today_stock,mean)\n",
    "        print()\n",
    "        print(\"Forecasted Prices for Next 7 days:\")\n",
    "        print(forecast_set)\n",
    "        today_stock=today_stock.round(2)\n",
    "        return render_template('result.html',quote=quote,arima_pred=round(arima_pred,2),lstm_pred=round(lstm_pred,2),\n",
    "                               lr_pred=round(lr_pred,2),open_s=today_stock['Open'].to_string(index=False),\n",
    "                               close_s=today_stock['Close'].to_string(index=False),adj_close=today_stock['Adj Close'].to_string(index=False),\n",
    "                               news_list=news_list,overall_sentiment=overall_sentiment,idea=idea,decision=decision,high_s=today_stock['High'].to_string(index=False),\n",
    "                               low_s=today_stock['Low'].to_string(index=False),vol=today_stock['Volume'].to_string(index=False),\n",
    "                               forecast_set=forecast_set,error_lr=round(error_lr,2),error_lstm=round(error_lstm,2),error_arima=round(error_arima,2))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15daf458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Tue Aug 29 09:40:39 2023\n",
    "\n",
    "@author: Nikhil Yadav\n",
    "\"\"\"\n",
    "\n",
    "#**************** IMPORT PACKAGES ********************\n",
    "from flask import Flask, render_template, request, flash, redirect, url_for\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import math, random\n",
    "from datetime import datetime\n",
    "import datetime as dt\n",
    "#import yfinance as yf\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "#************ FLASK *****************\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "#To control caching so as to save and retrieve plot figs on client side\n",
    "@app.after_request\n",
    "def add_header(response):\n",
    "    response.headers['Pragma'] = 'no-cache'\n",
    "    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'\n",
    "    response.headers['Expires'] = '0'\n",
    "    return response\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/stock-predictions')\n",
    "def stock_predictions():\n",
    "    return render_template('stock-predictions.html')\n",
    "\n",
    "@app.route('/coinvert')\n",
    "def coinvert():\n",
    "    return render_template('coinvert.html')\n",
    "\n",
    "@app.route('/about')\n",
    "def about():\n",
    "    return render_template('about.html')\n",
    "\n",
    "@app.route('/contact')\n",
    "def contact():\n",
    "    return render_template('contact.html')\n",
    "\n",
    "@app.route('/result', methods=['POST'])\n",
    "def result():\n",
    "    symbol = request.form['symbol']\n",
    "    \n",
    "    \n",
    "    # **************** FUNCTIONS TO FETCH DATA ***************************\n",
    "    \n",
    "    def get_historical(quote):\n",
    "        end = datetime.now()\n",
    "        start = datetime(end.year - 2, end.month, end.day)\n",
    "        data = yf.download(quote, start=start, end=end)\n",
    "        df = pd.DataFrame(data=data)\n",
    "        df.to_csv('' + quote + '.csv')\n",
    "        if df.empty:\n",
    "            ts = TimeSeries(key='N6A6QT6IBFJOPJ70', output_format='pandas')\n",
    "            data, meta_data = ts.get_daily_adjusted(symbol='NSE:' + quote, outputsize='full')\n",
    "            # Format df\n",
    "            # Last 2 yrs rows => 502, in ascending order => ::-1\n",
    "            data = data.head(503).iloc[::-1]\n",
    "            data = data.reset_index()\n",
    "            # Keep Required cols only\n",
    "            df = pd.DataFrame()\n",
    "            df['Date'] = data['date']\n",
    "            df['Open'] = data['1. open']\n",
    "            df['High'] = data['2. high']\n",
    "            df['Low'] = data['3. low']\n",
    "            df['Close'] = data['4. close']\n",
    "            df['Adj Close'] = data['5. adjusted close']\n",
    "            df['Volume'] = data['6. volume']\n",
    "            df.to_csv('' + quote + '.csv', index=False)\n",
    "        return\n",
    "\n",
    "    # ******************** ANN SECTION ********************\n",
    "    \n",
    "    # Define the parser function\n",
    "    def parser(x):\n",
    "        return datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "    # ************* ANN SECTION ********************\n",
    "    \n",
    "    def ANN_ALGO(df):\n",
    "        uniqueVals = df[\"Code\"].unique()\n",
    "        len(uniqueVals)\n",
    "        df = df.set_index(\"Code\")\n",
    "\n",
    "        def ann_model(train, test):\n",
    "            scaler = MinMaxScaler()\n",
    "            train_scaled = scaler.fit_transform(train)\n",
    "            test_scaled = scaler.transform(test)\n",
    "\n",
    "            X_train, y_train = train_scaled[:-1], train_scaled[1:]\n",
    "            X_test, y_test = test_scaled[:-1], test_scaled[1:]\n",
    "\n",
    "            model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "            model.fit(X_train, y_train)\n",
    "        \n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1))\n",
    "\n",
    "            return y_pred_inv\n",
    "\n",
    "        for company in uniqueVals[:10]:\n",
    "            data = (df.loc[company, :]).reset_index()\n",
    "            data['Price'] = data['Close']\n",
    "            Quantity_date = data[['Price', 'Date']]\n",
    "            Quantity_date.index = Quantity_date['Date'].map(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "            Quantity_date['Price'] = Quantity_date['Price'].map(lambda x: float(x))\n",
    "            Quantity_date = Quantity_date.fillna(Quantity_date.bfill())\n",
    "            Quantity_date = Quantity_date.drop(['Date'], axis=1)\n",
    "\n",
    "            fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "            plt.plot(Quantity_date)\n",
    "            plt.savefig('static/Trends.png')\n",
    "            plt.close(fig)\n",
    "\n",
    "            quantity = Quantity_date.values\n",
    "            size = int(len(quantity) * 0.80)\n",
    "            train, test = quantity[0:size], quantity[size:len(quantity)]\n",
    "\n",
    "            predictions = ann_model(train, test)\n",
    "\n",
    "            fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "            plt.plot(test[1:], label='Actual Price')\n",
    "            plt.plot(predictions, label='Predicted Price')\n",
    "            plt.legend(loc=4)\n",
    "            plt.savefig('static/ARIMA.png')\n",
    "            plt.close(fig)\n",
    "\n",
    "            #print()\n",
    "            ann_pred = predictions[-1][0]\n",
    "            print(\"Tomorrow's\", quote, \"Closing Price Prediction by ANN:\", ann_pred)\n",
    "\n",
    "            error_ann = math.sqrt(mean_squared_error(test[1:], predictions))\n",
    "            print(\"ANN RMSE:\", error_ann)\n",
    "\n",
    "            return ann_pred, error_ann\n",
    "        \n",
    "    # ************* GaussianProcessRegressor SECTION **********************\n",
    "\n",
    "    def PolynomialRegression_ALGO(df):\n",
    "        dataset_train = df.iloc[0:int(0.8 * len(df)), :]\n",
    "        dataset_test = df.iloc[int(0.8 * len(df)):, :]\n",
    "        training_set = dataset_train.iloc[:, 4:5].values\n",
    "\n",
    "        sc = MinMaxScaler(feature_range=(0, 1))\n",
    "        training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        for i in range(7, len(training_set_scaled)):\n",
    "            X_train.append(training_set_scaled[i - 7:i, 0])\n",
    "            y_train.append(training_set_scaled[i, 0])\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        X_forecast = np.append(X_train[-1, 1:], y_train[-1])\n",
    "\n",
    "        poly = PolynomialFeatures(degree=2)  # You can adjust the degree as needed\n",
    "        X_train_poly = poly.fit_transform(X_train)\n",
    "        X_forecast_poly = poly.transform(np.array(X_forecast).reshape(1, -1))\n",
    "\n",
    "        regressor = LinearRegression()\n",
    "        regressor.fit(X_train_poly, y_train)\n",
    "\n",
    "        real_stock_price = dataset_test.iloc[:, 4:5].values\n",
    "\n",
    "        dataset_total = pd.concat((dataset_train['Close'], dataset_test['Close']), axis=0)\n",
    "        testing_set = dataset_total[len(dataset_total) - len(dataset_test) - 7:].values\n",
    "        testing_set = testing_set.reshape(-1, 1)\n",
    "\n",
    "        testing_set = sc.transform(testing_set)\n",
    "\n",
    "        X_test = []\n",
    "        for i in range(7, len(testing_set)):\n",
    "            X_test.append(testing_set[i - 7:i, 0])\n",
    "        X_test = np.array(X_test)\n",
    "        X_test_poly = poly.transform(X_test)\n",
    "\n",
    "        predicted_stock_price_poly = regressor.predict(X_test_poly)\n",
    "        predicted_stock_price = sc.inverse_transform(predicted_stock_price_poly.reshape(-1, 1))\n",
    "\n",
    "        fig = plt.figure(figsize=(10.2, 6), dpi=65)\n",
    "        plt.plot(real_stock_price, label='Actual Price')\n",
    "        plt.plot(predicted_stock_price, label='Predicted Price')\n",
    "        plt.legend(loc=4)\n",
    "        plt.savefig('static/LSTM.png')\n",
    "        plt.close(fig)\n",
    "\n",
    "        error_poly = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "\n",
    "        forecasted_stock_price_poly = regressor.predict(X_forecast_poly)\n",
    "        forecasted_stock_price = sc.inverse_transform(forecasted_stock_price_poly.reshape(-1, 1))\n",
    "\n",
    "        poly_pred = forecasted_stock_price[0, 0]\n",
    "        print()\n",
    "        print(\"Tomorrow's\", quote, \"Closing Price Prediction by Polynomial Regression:\", poly_pred)\n",
    "        print(\"Polynomial Regression RMSE:\", error_poly)\n",
    "\n",
    "        return poly_pred, error_poly\n",
    "\n",
    "    \n",
    "    #***************** LINEAR REGRESSION SECTION ******************  \n",
    "    \n",
    "    def LIN_REG_ALGO(df):\n",
    "        #No of days to be forcasted in future\n",
    "        forecast_out = int(7)\n",
    "        #Price after n days\n",
    "        df['Close after n days'] = df['Close'].shift(-forecast_out)\n",
    "        #New df with only relevant data\n",
    "        df_new=df[['Close','Close after n days']]\n",
    "\n",
    "        #Structure data for train, test & forecast\n",
    "        #lables of known data, discard last 35 rows\n",
    "        y =np.array(df_new.iloc[:-forecast_out,-1])\n",
    "        y=np.reshape(y, (-1,1))\n",
    "        #all cols of known data except lables, discard last 35 rows\n",
    "        X=np.array(df_new.iloc[:-forecast_out,0:-1])\n",
    "        #Unknown, X to be forecasted\n",
    "        X_to_be_forecasted=np.array(df_new.iloc[-forecast_out:,0:-1])\n",
    "        \n",
    "        #Traning, testing to plot graphs, check accuracy\n",
    "        X_train=X[0:int(0.8*len(df)),:]\n",
    "        X_test=X[int(0.8*len(df)):,:]\n",
    "        y_train=y[0:int(0.8*len(df)),:]\n",
    "        y_test=y[int(0.8*len(df)):,:]\n",
    "        \n",
    "        # Feature Scaling===Normalization\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        sc = StandardScaler()\n",
    "        X_train = sc.fit_transform(X_train)\n",
    "        X_test = sc.transform(X_test)\n",
    "        \n",
    "        X_to_be_forecasted=sc.transform(X_to_be_forecasted)\n",
    "        \n",
    "        #Training\n",
    "        clf = LinearRegression(n_jobs=-1)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        #Testing\n",
    "        y_test_pred=clf.predict(X_test)\n",
    "        y_test_pred=y_test_pred*(1.04)\n",
    "        import matplotlib.pyplot as plt2\n",
    "        fig = plt2.figure(figsize=(10.2, 6), dpi=65)\n",
    "        plt2.plot(y_test,label='Actual Price' )\n",
    "        plt2.plot(y_test_pred,label='Predicted Price')\n",
    "        \n",
    "        plt2.legend(loc=4)\n",
    "        plt2.savefig('static/LR.png')\n",
    "        plt2.close(fig)\n",
    "        \n",
    "        error_lr = math.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        \n",
    "        #Forecasting\n",
    "        forecast_set = clf.predict(X_to_be_forecasted)\n",
    "        forecast_set=forecast_set*(1.04)\n",
    "        mean=forecast_set.mean()\n",
    "        lr_pred=forecast_set[0,0]\n",
    "        print()\n",
    "        print(\"Tomorrow's \",quote,\" Closing Price Prediction by Linear Regression: \",lr_pred)\n",
    "        print(\"Linear Regression RMSE:\",error_lr)\n",
    "        return df, lr_pred, forecast_set, mean, error_lr\n",
    "    \n",
    "    \n",
    "\n",
    "    #**************** SENTIMENT ANALYSIS **************************\n",
    "    \n",
    "    def retrieve_news_sentiment(symbol, api_key):\n",
    "        \n",
    "        # Define the URL for the news API\n",
    "        news_api_url = f'https://newsapi.org/v2/everything?q={symbol} stock&apiKey={api_key}'\n",
    "\n",
    "        try:\n",
    "            # Send an HTTP GET request to the news API\n",
    "            response = requests.get(news_api_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                # Parse the JSON response\n",
    "                news_data = response.json()\n",
    "\n",
    "                # Check if news articles are available\n",
    "                if 'articles' in news_data and len(news_data['articles']) > 0:\n",
    "                    news_list = []  # List of news headlines alongside polarity\n",
    "                    global_polarity = 0  # Polarity of all news headlines\n",
    "                    news_headlines_list = []  # List of news headlines only\n",
    "                    pos = 0  # Num of positive headlines\n",
    "                    neg = 0  # Num of negative headlines\n",
    "                    neutral = 0  # Num of neutral headlines\n",
    "\n",
    "                    for article in news_data['articles']:\n",
    "                        news_text = article['title']\n",
    "\n",
    "                        # Analyze the sentiment of the news headline\n",
    "                        analysis = TextBlob(news_text)\n",
    "                        polarity = analysis.sentiment.polarity\n",
    "                        global_polarity += polarity\n",
    "\n",
    "                        # Categorize the sentiment of the news headline\n",
    "                        if polarity > 0:\n",
    "                            sentiment = \"Positive\"\n",
    "                            pos += 1\n",
    "                        elif polarity < 0:\n",
    "                            sentiment = \"Negative\"\n",
    "                            neg += 1\n",
    "                        else:\n",
    "                            sentiment = \"Neutral\"\n",
    "                            neutral += 1\n",
    "\n",
    "                        news_list.append((news_text, sentiment))\n",
    "                        news_headlines_list.append(news_text)\n",
    "\n",
    "                    # Determine the overall sentiment based on global_polarity\n",
    "                    if global_polarity > 0:\n",
    "                        overall_sentiment = \"Overall Positive\"\n",
    "                    elif global_polarity < 0:\n",
    "                        overall_sentiment = \"Overall Negative\"\n",
    "                    else:\n",
    "                        overall_sentiment = \"Overall Neutral\"\n",
    "\n",
    "                    # Create a pie chart for sentiment analysis\n",
    "                    sentiment_data = pd.DataFrame({'Sentiment': ['Positive', 'Negative', 'Neutral'],\n",
    "                                               'Count': [pos, neg, neutral]})\n",
    "                    plt.figure(figsize=(4.9, 4.9))\n",
    "                    plt.pie(sentiment_data['Count'], labels=sentiment_data['Sentiment'], autopct='%1.1f%%', startangle=100)\n",
    "                    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "                    # Save the figure as 'static/SA.png'\n",
    "                    plt.savefig('static/SA.png')\n",
    "\n",
    "                    # Close the figure\n",
    "                    plt.close()\n",
    "\n",
    "                    return global_polarity, news_list, overall_sentiment, pos, neg, neutral\n",
    "                else:\n",
    "                    return 0, [], \"No News Found\", 0, 0, 0\n",
    "            else:\n",
    "                return 0, [], f\"Failed to Fetch News (Status Code: {response.status_code})\", 0, 0, 0\n",
    "\n",
    "        except Exception as e:\n",
    "            return 0, [], f\"Error: {str(e)}\", 0, 0, 0\n",
    "\n",
    "        \n",
    "    def recommending(df, global_polarity,today_stock,mean):\n",
    "        if today_stock.iloc[-1]['Close'] < mean:\n",
    "            if global_polarity > 0:\n",
    "                idea=\"RISE\"\n",
    "                decision=\"BUY\"\n",
    "                print()\n",
    "                print(\"##############################################################################\")\n",
    "                print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "            elif global_polarity <= 0:\n",
    "                idea=\"FALL\"\n",
    "                decision=\"SELL\"\n",
    "                print()\n",
    "                print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "        else:\n",
    "            idea=\"FALL\"\n",
    "            decision=\"SELL\"\n",
    "            print()\n",
    "            print(\"According to the ML Predictions and Sentiment Analysis of News, a\",idea,\"in\",quote,\"stock is expected => \",decision)\n",
    "        return idea, decision\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #**************GET DATA ***************************************\n",
    "    \n",
    "    quote=symbol\n",
    "    \n",
    "    #Try-except to check if valid stock symbol\n",
    "    try:\n",
    "        df = pd.read_csv(''+quote+'.csv')\n",
    "    except:\n",
    "        return render_template('stock-predictions.html',msg=\"Stock Symbol Not Found. Please Enter a Valid Stock Symbol\")\n",
    "    else:\n",
    "    \n",
    "        #************** PREPROCESSUNG ***********************\n",
    "        \n",
    "        df = pd.read_csv(''+quote+'.csv')\n",
    "        print(\"Today's\",quote,\"Stock Data: \")\n",
    "        today_stock=df.iloc[-1:]\n",
    "        print(today_stock)\n",
    "        df = df.dropna()\n",
    "        code_list=[]\n",
    "        for i in range(0,len(df)):\n",
    "            code_list.append(quote)\n",
    "        df2=pd.DataFrame(code_list,columns=['Code'])\n",
    "        df2 = pd.concat([df2, df], axis=1)\n",
    "        df=df2\n",
    "\n",
    "\n",
    "        arima_pred, error_arima=ANN_ALGO(df)\n",
    "        lstm_pred, error_lstm=PolynomialRegression_ALGO(df)\n",
    "        df, lr_pred, forecast_set,mean,error_lr=LIN_REG_ALGO(df)\n",
    "        \n",
    "        # Assuming you have an 'api_key' variable defined with your API key\n",
    "        api_key = 'caae80f5ad8b451e9fc0856027ddbb34'\n",
    "        #symbol = quote\n",
    "\n",
    "        # Call the retrieve_news_sentiment function with the 'api_key' argument\n",
    "        polarity, news_list, overall_sentiment, pos, neg, neutral = retrieve_news_sentiment(quote, api_key)\n",
    "        \n",
    "        idea, decision=recommending(df, polarity,today_stock,mean)\n",
    "        print()\n",
    "        print(\"Forecasted Prices for Next 7 days:\")\n",
    "        print(forecast_set)\n",
    "        today_stock=today_stock.round(2)\n",
    "        return render_template('result.html',quote=quote,arima_pred=round(arima_pred,2),lstm_pred=round(lstm_pred,2),\n",
    "                               lr_pred=round(lr_pred,2),open_s=today_stock['Open'].to_string(index=False),\n",
    "                               close_s=today_stock['Close'].to_string(index=False),adj_close=today_stock['Adj Close'].to_string(index=False),\n",
    "                               news_list=news_list,overall_sentiment=overall_sentiment,idea=idea,decision=decision,high_s=today_stock['High'].to_string(index=False),\n",
    "                               low_s=today_stock['Low'].to_string(index=False),vol=today_stock['Volume'].to_string(index=False),\n",
    "                               forecast_set=forecast_set,error_lr=round(error_lr,2),error_lstm=round(error_lstm,2),error_arima=round(error_arima,2))\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
